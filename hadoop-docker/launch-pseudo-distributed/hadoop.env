# Variables para los archivos de configuracion de hadoop
#
# Estas variables son utilizadas por el archivo start-hadoop.sh para inicializar
# los archivos core-site.xml, hdfs-site.xml, mapred-site.xml y yarn-site.xml
# Los regenera cada vez que se ejecuta el contenedor.
#
# Estructura de las variables
# {prefijo-archivo-hadoop}_{nombre-variable-hadoop}={valor-variable}
# {prefijo-archivo-hadoop} >>> ( CORE_SITE | HDFS_SITE | MAPRED_SITE | YARN_SITE )
# {nombre-variable-hadoop} >>> mismo nombre que la variable de hadoop pero hay que reemplazar ciertos carateres.
# Caracteres reemplazo >>> (":" > "_____" | "_" > "____" | "-" > "___"  | "@" > "__" | "." > "_" )
#
# Ejemplo: 
#       dfs.replication >>> HDFS_SITE_dfs_replication
#       yarn.nodemanager.aux-services >>> YARN_SITE_yarn_nodemanager_aux___services

# Global
HADOOP_DATA=/hadoop-data

# core-site.xml
CORE_SITE_fs_defaultFS=hdfs://hadoop-master:9000
CORE_SITE_fs_default_name=hdfs://hadoop-master:9000
CORE_SITE_hadoop_tmp_dir=/tmp/hadoop-tmp
CORE_SITE_hadoop_proxyuser_root_hosts=*
CORE_SITE_hadoop_proxyuser_root_groups=*

# hdfs-site.xml
HDFS_SITE_dfs_replication=1
HDFS_SITE_dfs_name_dir=file:///hadoop-data/hdfs/namenode
HDFS_SITE_dfs_data_dir=file:///hadoop-data/hdfs/datanode
HDFS_SITE_dfs_namenode_checkpoint_dir=file:///hadoop-data/hdfs/namesecondary
HDFS_SITE_heartbeat_recheck_interval=15
HDFS_SITE_dfs_block_size=268435456

# mapred-site.xml
MAPRED_SITE_mapreduce_framework_name=yarn
MAPRED_SITE_yarn_app_mapreduce_am_env=HADOOP_MAPRED_HOME=$HADOOP_HOME
MAPRED_SITE_mapreduce_map_env=HADOOP_MAPRED_HOME=$HADOOP_HOME
MAPRED_SITE_mapreduce_reduce_env=HADOOP_MAPRED_HOME=$HADOOP_HOME

# yarn-site.xml
YARN_SITE_yarn_nodemanager_aux___services=mapreduce_shuffle
YARN_SITE_yarn_nodemanager_aux___services_mapreduce____shuffle_class=org.apache.hadoop.mapred.ShuffleHandler
YARN_SITE_yarn_nodemanager_local___dirs=file:///hadoop-data/yarn
YARN_SITE_yarn_resourcemanager_hostname=hadoop-master